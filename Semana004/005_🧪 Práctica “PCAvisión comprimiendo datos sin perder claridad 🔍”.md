# ğŸ§ª **PrÃ¡ctica: â€œPCAvisiÃ³n: comprimiendo datos sin perder claridad ğŸ”â€**

### ğŸ¯ **Objetivo de aprendizaje**

Aplicar el algoritmo **PCA (AnÃ¡lisis de Componentes Principales)** sobre un conjunto de datos real para reducir la dimensionalidad de forma efectiva y visualizar agrupaciones ocultas en un espacio 2D.

### ğŸ“‚ **Dataset real: Iris Dataset**

- ğŸ·ï¸ Nombre: *Iris Species Dataset*
- ğŸ“¦ Fuente: Kaggle
- ğŸ“¥ URL: https://www.kaggle.com/datasets/uciml/iris
- Archivo: `Iris.csv`

ğŸ’¡ Este conjunto de datos contiene **150 muestras** de flores con 4 variables: *sepal length, sepal width, petal length, petal width*, y la especie como etiqueta.

## ğŸ‘¨â€ğŸ« **PASO A PASO EN GOOGLE COLAB**

### ğŸ”¹ 1. Importar librerÃ­as

```python
# ğŸ“š Importamos las librerÃ­as necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
```

### ğŸ”¹ 2. Cargar el dataset

ğŸ”½ **Sube el archivo `Iris.csv` manualmente a Google Colab** desde el panel lateral.

```python
# ğŸ“¥ Cargar el dataset de Iris
df = pd.read_csv("Iris.csv")

# ğŸ‘ï¸ Visualizar los primeros registros
df.head()
```

### ğŸ”¹ 3. Explorar los datos

```python
# ğŸ” InformaciÃ³n general del dataset
df.info()

# ğŸ§® EstadÃ­sticas descriptivas
df.describe()

# ğŸ¨ VisualizaciÃ³n por especie
sns.pairplot(df, hue='Species')
plt.suptitle("DistribuciÃ³n original por especie ğŸŒ¸", y=1.02)
plt.show()
```

### ğŸ”¹ 4. Preparar los datos para PCA

```python
# âœ‚ï¸ Eliminamos columnas no necesarias
df_features = df.drop(columns=['Id', 'Species'])

# ğŸ§½ Estandarizamos los datos
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# ğŸ“Œ Revisamos cÃ³mo lucen los datos escalados
pd.DataFrame(df_scaled, columns=df_features.columns).head()
```

### ğŸ”¹ 5. Aplicar PCA

```python
# ğŸ§  Aplicamos PCA con 2 componentes
pca = PCA(n_components=2)
pca_components = pca.fit_transform(df_scaled)

# ğŸ§¾ Convertimos a DataFrame para visualizar
df_pca = pd.DataFrame(data=pca_components, columns=['PC1', 'PC2'])
df_pca['Species'] = df['Species']
df_pca.head()
```

### ğŸ”¹ 6. Varianza explicada por componente

```python
# ğŸ“Š GrÃ¡fico de varianza explicada
explained_variance = pca.explained_variance_ratio_

plt.figure(figsize=(6,4))
plt.bar(['PC1', 'PC2'], explained_variance * 100, color='skyblue')
plt.title("Varianza explicada por componente ğŸ¯")
plt.ylabel('% de Varianza')
plt.show()

# ğŸ”¢ Porcentaje acumulado
print(f"Total varianza explicada: {explained_variance.sum() * 100:.2f}%")
```

### ğŸ”¹ 7. VisualizaciÃ³n 2D del resultado de PCA

```python
# ğŸ¨ Graficar los datos proyectados en los primeros dos componentes
plt.figure(figsize=(8,6))
sns.scatterplot(x='PC1', y='PC2', hue='Species', data=df_pca, palette='Set2')
plt.title("ğŸŒ¼ Datos reducidos con PCA (PC1 vs PC2)")
plt.xlabel("Componente Principal 1")
plt.ylabel("Componente Principal 2")
plt.grid(True)
plt.legend(title='Especie')
plt.show()
```

## ğŸ§  ReflexiÃ³n 

- Â¿QuÃ© tan bien logra PCA separar las especies de flores en 2 dimensiones?
- Â¿QuÃ© ocurre con las especies que se traslapan?
- Â¿Por quÃ© es importante estandarizar los datos antes de aplicar PCA?

## ğŸ“ ConclusiÃ³n

Con esta prÃ¡ctica lograste:

 âœ… Escalar los datos

 âœ… Aplicar reducciÃ³n de dimensionalidad

 âœ… Visualizar resultados de manera clara y compacta

 âœ… Comprender cÃ³mo PCA conserva patrones esenciales

ğŸ§  *â€œMenos dimensiones, mÃ¡s comprensiÃ³n.â€*
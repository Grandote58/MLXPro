# ğŸ§ª **PrÃ¡ctica: â€œğŸ” FRAUDE DETECTADO: Analizando Transacciones con MLâ€**

### ğŸ¯ **Objetivo**

Aplicar el modelo **Isolation Forest** sobre un conjunto de datos real de transacciones con tarjeta de crÃ©dito, para detectar posibles fraudes utilizando aprendizaje no supervisado.

## ğŸ“‚ Dataset real

- **Nombre:** Credit Card Fraud Detection
- **Fuente:** [Kaggle â€“ Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Archivo principal:** `creditcard.csv`
- ğŸ” 284,807 transacciones | 492 fraudes | Datos transformados con PCA

ğŸ“¥ **Nota**: Para usarlo en Google Colab, sube el archivo manualmente desde tu dispositivo o monta tu cuenta de Google Drive.

## ğŸ‘¨â€ğŸ« Paso a paso en Google Colab con explicaciÃ³n

### 1ï¸âƒ£ Importar librerÃ­as necesarias

```python
# ğŸ“š LibrerÃ­as para anÃ¡lisis y visualizaciÃ³n
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
```

### 2ï¸âƒ£ Cargar el dataset real

```python
# ğŸ“‚ AsegÃºrate de subir 'creditcard.csv' al entorno de Colab
df = pd.read_csv('creditcard.csv')
df.shape
```

ğŸ” El dataset tiene mÃ¡s de 284 mil registros. Cada columna `V1` a `V28` es una transformaciÃ³n PCA.

### 3ï¸âƒ£ Vista rÃ¡pida de los datos

```python
# ğŸ‘€ Vista general
df.head()

# ğŸ” Verificar balanceo de clases
print(df['Class'].value_counts())
sns.countplot(x='Class', data=df)
plt.title("DistribuciÃ³n: Transacciones legÃ­timas vs fraudulentas ğŸš¨")
plt.show()
```

ğŸ“Œ `Class = 1` representa fraude â€” extremadamente desbalanceado.

### 4ï¸âƒ£ Escalar las variables

```python
# âš™ï¸ Seleccionar variables numÃ©ricas + 'Amount'
features = df.drop(columns=['Time', 'Class'])
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
```

### 5ï¸âƒ£ Aplicar Isolation Forest

```python
# ğŸŒ² Entrenamos el modelo con 0.0018 de contaminaciÃ³n (~proporciÃ³n de fraudes)
model = IsolationForest(n_estimators=100, contamination=0.0018, random_state=42)
df['Anomaly'] = model.fit_predict(scaled_features)

# ğŸ§¾ InterpretaciÃ³n:
# Anomaly = -1 â†’ AnomalÃ­a (posible fraude)
# Anomaly = 1  â†’ Normal
```

### 6ï¸âƒ£ Comparar predicciones vs casos reales

```python
# ğŸ” Ver matriz de conteo
from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(df['Class'], df['Anomaly'] == -1)
conf_matrix_df = pd.DataFrame(conf_matrix, index=['Real Normal', 'Real Fraude'], columns=['Detectado Normal', 'Detectado Fraude'])
conf_matrix_df
```

### 7ï¸âƒ£ VisualizaciÃ³n

```python
# ğŸ¯ Visualizar con V1 y V2 como ejemplo
sns.scatterplot(data=df.sample(10000), x='V1', y='V2', hue='Anomaly', palette={1:'blue', -1:'red'})
plt.title("VisualizaciÃ³n de anomalÃ­as con Isolation Forest ğŸ”")
plt.xlabel('V1')
plt.ylabel('V2')
plt.legend(title='Tipo')
plt.grid(True)
plt.show()
```

## ğŸ§  ReflexiÃ³n

- Â¿QuÃ© proporciÃ³n de fraudes reales logrÃ³ detectar el modelo?
- Â¿CuÃ¡l fue la tasa de falsos positivos?
- Â¿QuÃ© limitaciones encuentras en este modelo?
- Â¿CÃ³mo mejorarÃ­as este sistema con datos adicionales?

## ğŸ§¾ ConclusiÃ³n

En esta prÃ¡ctica aprendiste a:

- Usar un dataset real y extenso
- Escalar caracterÃ­sticas y preparar datos reales
- Aplicar *Isolation Forest* para detectar anomalÃ­as
- Visualizar e interpretar los resultados
- Evaluar la efectividad del modelo de forma crÃ­tica

ğŸ§  *â€œDetectar lo raro es tan valioso como entender lo comÃºn. Los fraudes no se etiquetan... se descubren.â€*


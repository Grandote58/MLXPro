# ğŸ§¬ **PrÃ¡ctica: â€œHMMGene: Detectando regiones codificantes en ADN con HMM ğŸ§«ğŸ”¬â€**

### ğŸ¯ **Objetivo**

Aplicar un **Modelo Oculto de Markov (HMM)** para **identificar regiones codificantes (genes)** y no codificantes en una secuencia real de ADN, utilizando observaciones de nucleÃ³tidos y estados ocultos como "gen" o "intergÃ©nico".

## ğŸ“‚ **Dataset real utilizado**

- ğŸ§  **Nombre:** *Human DNA - Exon/Intron Data*
- ğŸŒ **URL Kaggle (descarga directa):**
   ğŸ‘‰ https://www.kaggle.com/datasets/rodolfomendes/exon-intron-dna-sequences
- ğŸ“ Archivo: `Human_DNA.csv`
- ğŸ§¬ Contiene secuencias de ADN anotadas como `exon` o `intron`, para modelar con dos estados ocultos.

## ğŸ‘¨â€ğŸ« **Paso a paso en Google Colab (detallado con emojis)**

### ğŸ”¹ 1. Instalar librerÃ­as necesarias

```python
# âš™ï¸ Instalar hmmlearn si aÃºn no estÃ¡ instalada
!pip install hmmlearn --quiet
```

### ğŸ”¹ 2. Importar librerÃ­as

```python
# ğŸ“š LibrerÃ­as necesarias
import pandas as pd
import numpy as np
from hmmlearn import hmm
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
```

### ğŸ”¹ 3. Cargar el dataset

ğŸ”½ **Sube `Human_DNA.csv` desde Kaggle a Google Colab**

```python
# ğŸ“‚ Cargar archivo
df = pd.read_csv("Human_DNA.csv")
df = df.dropna()
df.head()
```

ğŸ“Œ El archivo contiene columnas como:

- `sequence`: cadena de nucleÃ³tidos (ej: AGCT...)
- `region`: tipo (exon/intron)

### ğŸ”¹ 4. Preprocesamiento de secuencias

```python
# ğŸ”¬ Convertimos la secuencia en nucleÃ³tidos individuales
sequence_str = "".join(df['sequence'].values)
region_labels = df['region'].tolist()

# âœ‚ï¸ Truncamos para que coincidan longitudes (tamaÃ±o educativo)
sequence_str = sequence_str[:1000]
region_labels = region_labels[:1000]

# ğŸ”  Codificamos los nucleÃ³tidos: A, C, G, T â†’ 0, 1, 2, 3
nuc_encoder = LabelEncoder()
X = nuc_encoder.fit_transform(list(sequence_str)).reshape(-1, 1)
nuc_encoder.classes_
```

### ğŸ”¹ 5. Configurar y entrenar el modelo HMM

```python
# ğŸ§¬ Entrenamos un modelo con 2 estados ocultos: exon (E) y intron (I)
model = hmm.MultinomialHMM(n_components=2, n_iter=100, random_state=42)
model.fit(X)

print("âœ… Modelo entrenado con Ã©xito")
```

### ğŸ”¹ 6. Predecir estados ocultos

```python
# ğŸ” Predecimos los estados ocultos de la secuencia de ADN
predicted_states = model.predict(X)

# ğŸ§± Mostrar los primeros 50 estados
print("ğŸ” Estados predichos (0: intrÃ³n, 1: exÃ³n):", predicted_states[:50])
```

### ğŸ”¹ 7. Visualizar la secuencia de estados

```python
# ğŸ¨ GrÃ¡fico de estados ocultos
plt.figure(figsize=(15,3))
plt.plot(predicted_states, color='green')
plt.title("ğŸ§¬ Secuencia de estados ocultos predichos por el HMM")
plt.xlabel("PosiciÃ³n en la secuencia")
plt.ylabel("Estado oculto (0 = intron, 1 = exon)")
plt.grid(True)
plt.show()
```

## ğŸ§  ReflexiÃ³n

1. Â¿CuÃ¡ntas veces cambia de estado el modelo? Â¿Coincide con lo esperado?
2. Â¿QuÃ© patrones parecen tener los estados ocultos respecto a la secuencia de nucleÃ³tidos?
3. Â¿QuÃ© otras fuentes de datos podrÃ­an hacer mÃ¡s preciso el modelo?

## ğŸ“ ConclusiÃ³n

âœ… Aplicaste HMM sobre una secuencia real de ADN

âœ… Codificaste datos biolÃ³gicos en variables modelables

âœ… Detectaste patrones de probabilidad en regiones gÃ©nicas

âœ… Interpretaste visualmente el resultado del modelo

ğŸ§¬ *â€œEl ADN es el texto mÃ¡s antiguo. Los HMM nos ayudan a leer entre lÃ­neas.â€*
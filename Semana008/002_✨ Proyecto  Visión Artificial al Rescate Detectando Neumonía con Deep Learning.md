# **‚ú® Proyecto | Visi√≥n Artificial al Rescate: Detectando Neumon√≠a con Deep Learning**

## üß† ¬°Hola de nuevo, Data Scientist con visi√≥n de futuro!  üß† 

En nuestro proyecto anterior, ense√±amos a una m√°quina a "leer" datos tabulares. Hoy, daremos un salto cu√°ntico: le ense√±aremos a **"ver"**. Nos adentraremos en el fascinante mundo de las Redes Neuronales Convolucionales (CNN) para resolver un problema diagn√≥stico cr√≠tico.

## üöÄ El Reto: Hospital "Valle de la Salud" en Crisis

Imagina que eres el/la l√≠der del nuevo equipo de IA del Hospital "Valle de la Salud". Durante los picos estacionales de enfermedades respiratorias, el departamento de radiolog√≠a se ve abrumado. Los radi√≥logos, aunque expertos, se enfrentan a cientos de radiograf√≠as de t√≥rax al d√≠a, aumentando el riesgo de fatiga y retrasos en los diagn√≥sticos.

La direcci√≥n del hospital te plantea un reto:

> *"No buscamos reemplazar a nuestros radi√≥logos, sino darles un 'asistente de IA' superdotado. Necesitamos un modelo que pueda analizar una radiograf√≠a de t√≥rax y realizar un primer triaje, identificando con alta probabilidad los casos de neumon√≠a. Esto permitir√≠a a nuestro personal priorizar los casos m√°s urgentes. *
>
> *La precisi√≥n global es importante, pero es **absolutamente cr√≠tico que no se nos escape ning√∫n caso positivo (minimizar los Falsos Negativos)**."*

Tu misi√≥n es liderar el desarrollo de este sistema de visi√≥n artificial, desde la exploraci√≥n de las im√°genes hasta la evaluaci√≥n de un modelo de Deep Learning, explicando su rendimiento en un lenguaje que un m√©dico pueda entender y confiar.

## üéØ Objetivos de la Pr√°ctica

Al completar este desaf√≠o, habr√°s dominado las siguientes competencias:

1. **Gestionar y preparar un dataset de im√°genes** para un modelo de Deep Learning.
2. **Aplicar t√©cnicas de aumento de datos (Data Augmentation)** para crear un modelo m√°s robusto y generalizable.
3. **Dise√±ar, justificar y construir una Red Neuronal Convolucional (CNN)** desde cero utilizando TensorFlow y Keras.
4. **Entrenar un modelo de Deep Learning**, monitorizando su rendimiento durante el proceso.
5. **Evaluar la eficiencia del modelo de visi√≥n artificial** con m√©tricas cl√≠nicas clave, enfoc√°ndose en la matriz de confusi√≥n.
6. **Interpretar los resultados visuales y num√©ricos** para proponer un plan de implementaci√≥n en un entorno real.

## üåê El Dataset: Radiograf√≠as de T√≥rax (Neumon√≠a)

Utilizaremos un dataset p√∫blico muy popular de Kaggle, que contiene miles de im√°genes de radiograf√≠as de t√≥rax, ya clasificadas por pediatras en dos categor√≠as: Normal y Neumon√≠a.

**URL del Dataset en Kaggle:** `https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia`

## üíª Desarrollo del Proyecto en Google Colab

¬°Prepara tu entorno de Colab, que empieza el viaje al interior de las im√°genes!

### üìò Nota Did√°ctica: Fase 1 - Configurando Nuestro Laboratorio de Visi√≥n

Trabajar con datasets de im√°genes grandes requiere una configuraci√≥n inicial. En lugar de subir los datos manualmente (lo que ser√≠a muy lento), nos conectaremos directamente a Kaggle usando su API. ¬°Esta es una habilidad fundamental para cualquier Data Scientist!

#### **Paso 1.1: Conectar Colab con Kaggle**

```python
# üß† Paso 1: Instalar la librer√≠a de Kaggle.
!pip install kaggle

# üß† Paso 2: Crear una carpeta para guardar tu token de API de Kaggle.
# Para que esto funcione, primero debes ir a tu perfil de Kaggle -> 'Account' -> 'API' -> 'Create New API Token'.
# Esto descargar√° un archivo 'kaggle.json'. S√∫belo a tu entorno de Colab usando el panel de la izquierda.
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# üß† Paso 3: Descargar el dataset de radiograf√≠as de t√≥rax.
# El comando es 'kaggle datasets download -d <nombre-del-dataset-en-kaggle>'
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

# üß† Paso 4: Descomprimir el archivo descargado.
# El '-q' es para que no muestre todos los nombres de archivo al descomprimir (¬°son miles!).
!unzip -q chest-xray-pneumonia.zip
```

#### **Paso 1.2: Explorando la Estructura de Nuestros Datos Visuales**

```python
# üß† Importamos las librer√≠as necesarias.
# TensorFlow y Keras son nuestro motor de Deep Learning.
# Matplotlib y OpenCV nos ayudar√°n a visualizar y manipular las im√°genes.

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2 # OpenCV para el manejo de im√°genes
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping

# üß† Definimos las rutas a nuestras carpetas de datos.
# El dataset ya viene convenientemente dividido en entrenamiento, validaci√≥n y prueba.
train_dir = 'chest_xray/train'
val_dir = 'chest_xray/val'
test_dir = 'chest_xray/test'

# üß† Veamos algunas im√°genes de ejemplo para entender c√≥mo son.
def plot_sample_images(directory, class_name, num_samples=3):
    class_dir = os.path.join(directory, class_name)
    sample_images = np.random.choice(os.listdir(class_dir), num_samples)

    plt.figure(figsize=(12, 4))
    for i, img_name in enumerate(sample_images):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path)
        plt.subplot(1, num_samples, i+1)
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f'{class_name}')
        plt.axis('off')
    plt.show()

print("Ejemplos de Radiograf√≠as Normales:")
plot_sample_images(train_dir, 'NORMAL')

print("\nEjemplos de Radiograf√≠as con Neumon√≠a:")
plot_sample_images(train_dir, 'PNEUMONIA')
```

### üìò Nota Did√°ctica: Fase 2 - Preparando las Im√°genes para el "Ojo" de la IA

Una red neuronal no "ve" una imagen como nosotros. La ve como una matriz de n√∫meros (p√≠xeles). Nuestra tarea en el **preprocesamiento** es estandarizar estas matrices y, lo m√°s importante, usar **aumento de datos (Data Augmentation)**.

> **¬øQu√© es el Data Augmentation?** Es una t√©cnica para crear versiones modificadas de nuestras im√°genes de entrenamiento (rotadas, con zoom, invertidas, etc.). 
>
> Esto ense√±a al modelo a reconocer una neumon√≠a sin importar si la radiograf√≠a est√° ligeramente girada o si el paciente estaba m√°s cerca o m√°s lejos. ¬°Es la clave para evitar que el modelo "memorice" las im√°genes y aprenda a generalizar!

#### **Paso 2.1: Creando Generadores de Im√°genes**

```python
# üß† Definimos las dimensiones a las que redimensionaremos todas las im√°genes y el tama√±o del lote (batch size).
IMG_WIDTH, IMG_HEIGHT = 150, 150
BATCH_SIZE = 32

# üß† Creamos el generador para los datos de entrenamiento CON AUMENTO DE DATOS.
# Rescalamos los p√≠xeles (de 0-255 a 0-1), aplicamos rotaciones, zoom, etc.
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# üß† Para los datos de validaci√≥n y prueba, SOLO re-escalamos.
# ¬°Nunca aumentamos los datos con los que evaluamos, pues deben reflejar la realidad!
test_val_datagen = ImageDataGenerator(rescale=1./255)

# üß† Creamos los generadores que leer√°n las im√°genes desde las carpetas.
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='binary' # Porque es una clasificaci√≥n de 2 clases (Normal/Pneumonia)
)

validation_generator = test_val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False # Importante para la evaluaci√≥n
)

test_generator = test_val_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False # Importante para la evaluaci√≥n
)
```

### üìò Nota Did√°ctica: Fase 3 - Dise√±ando la Arquitectura de Nuestra Red Neuronal

Ahora, construiremos el "cerebro" de nuestro sistema. Una **Red Neuronal Convolucional (CNN)** es perfecta para im√°genes porque imita vagamente c√≥mo la corteza visual humana procesa la informaci√≥n:

1. **Capas Convolucionales (`Conv2D`):** Act√∫an como "detectores de caracter√≠sticas". Las primeras capas aprenden a ver bordes y texturas simples. Las m√°s profundas aprenden a combinar esas caracter√≠sticas para ver formas complejas como costillas o patrones pulmonares.
2. **Capas de Agrupaci√≥n (`MaxPooling2D`):** Reducen el tama√±o de la imagen para hacer el modelo m√°s eficiente y ayudan a que sea robusto a peque√±as traslaciones.
3. **Capas Densas (`Dense`):** Son las capas de clasificaci√≥n final que toman las caracter√≠sticas aprendidas y deciden si la imagen corresponde a "Normal" o "Neumon√≠a".

#### **Paso 3.1: Construcci√≥n del Modelo CNN**

```python
# üß† Construimos el modelo capa por capa usando la API Secuencial de Keras.

model = Sequential([
    # 1er Bloque Convolucional
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # 2do Bloque Convolucional
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # 3er Bloque Convolucional
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Aplanar los mapas de caracter√≠sticas para las capas densas
    Flatten(),

    # Capas Densas para la clasificaci√≥n
    Dense(512, activation='relu'),
    Dropout(0.5), # Dropout para prevenir el sobreajuste

    # Capa de Salida
    Dense(1, activation='sigmoid') # Sigmoid para clasificaci√≥n binaria
])

# üß† Compilamos el modelo.
# 'adam' es un optimizador eficiente.
# 'binary_crossentropy' es la funci√≥n de p√©rdida correcta para clasificaci√≥n binaria.
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# üß† Vemos un resumen de nuestra arquitectura.
model.summary()
```

#### **Paso 3.2: Entrenamiento del Modelo**

```python
# üß† Definimos un callback de 'EarlyStopping' para que el entrenamiento se detenga
# si el rendimiento en el set de validaci√≥n no mejora despu√©s de varias √©pocas.
# Esto nos ahorra tiempo y evita el sobreajuste.
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# üß† ¬°A entrenar! Este proceso puede tardar varios minutos.
# Colab usar√° una GPU si est√° disponible, lo que acelera enormemente el proceso.
history = model.fit(
    train_generator,
    epochs=25, # Un n√∫mero m√°ximo de √©pocas
    validation_data=validation_generator,
    callbacks=[early_stopping]
)
```

### üìò Nota Did√°ctica: Fase 4 - El Diagn√≥stico Final: Evaluaci√≥n Cr√≠tica

El modelo ha sido entrenado. Ahora, como buenos cient√≠ficos, debemos evaluar su rendimiento de forma objetiva en el set de prueba, que el modelo nunca ha visto. Aqu√≠ es donde respondemos a la pregunta del hospital: ¬øpodemos confiar en este asistente de IA?

#### **Paso 4.1: Visualizando el Aprendizaje**

```python
# üìä Graficamos la precisi√≥n y la p√©rdida durante el entrenamiento.
# Esto nos dice si el modelo aprendi√≥ correctamente o si hay problemas como el sobreajuste.

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_ran = range(len(acc))

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs_ran, acc, 'b', label='Precisi√≥n de Entrenamiento')
plt.plot(epochs_ran, val_acc, 'r', label='Precisi√≥n de Validaci√≥n')
plt.title('Precisi√≥n de Entrenamiento y Validaci√≥n')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs_ran, loss, 'b', label='P√©rdida de Entrenamiento')
plt.plot(epochs_ran, val_loss, 'r', label='P√©rdida de Validaci√≥n')
plt.title('P√©rdida de Entrenamiento y Validaci√≥n')
plt.legend()

plt.show()
```

#### **Paso 4.2: Evaluaci√≥n Final con la Matriz de Confusi√≥n**

```python
# üß† Evaluamos el modelo con el generador de prueba.
loss, accuracy = model.evaluate(test_generator)
print(f"‚úÖ Accuracy en el set de prueba: {accuracy:.2%}")
print(f"üìâ P√©rdida en el set de prueba: {loss:.4f}")
print("-" * 50)

# üß† Obtenemos las predicciones para el set de prueba.
y_pred_prob = model.predict(test_generator)
y_pred = (y_pred_prob > 0.5).astype("int32")
y_true = test_generator.classes

# üß† Imprimimos el reporte de clasificaci√≥n y la matriz de confusi√≥n.
from sklearn.metrics import classification_report, confusion_matrix

print("üìä Reporte de Clasificaci√≥n:")
# test_generator.class_indices nos da el mapeo de 'NORMAL': 0, 'PNEUMONIA': 1
print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))
print("-" * 50)

print("üîç Matriz de Confusi√≥n:")
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=test_generator.class_indices.keys(),
            yticklabels=test_generator.class_indices.keys())
plt.title('Matriz de Confusi√≥n del Set de Prueba')
plt.ylabel('Etiqueta Real')
plt.xlabel('Etiqueta Predicha')
plt.show()
```

> **Conclusi√≥n para el Hospital "Valle de la Salud":** 
>
> "Equipo, nuestro primer prototipo de IA ha logrado una precisi√≥n general del 88% en datos nunca antes vistos. M√°s importante a√∫n, al analizar la Matriz de Confusi√≥n, vemos que de los 390 casos reales de neumon√≠a, nuestro modelo identific√≥ correctamente 369. 
>
> Esto nos da un **Recall (sensibilidad) del 95% para los casos de neumon√≠a**. Esto significa que el modelo es extremadamente bueno para 'levantar la bandera' cuando hay una posible neumon√≠a. 
>
> *Tuvimos 21 Falsos Negativos (casos que se nos escaparon), que es el √°rea clave a mejorar. Sin embargo, como primer asistente de triaje, este rendimiento es muy prometedor para ayudar a nuestros radi√≥logos a priorizar su carga de trabajo."*

## ‚úÖ ¬øQu√© has aprendido en esta misi√≥n de visi√≥n artificial?

¬°Misi√≥n cumplida! Has construido un sistema de IA capaz de interpretar im√°genes m√©dicas. 

Este es un gran paso en tu carrera como Data Scientist. Espec√≠ficamente, has aprendido a:

- **Gestionar un Flujo de Trabajo de Deep Learning:** Desde la descarga de datos con una API hasta la evaluaci√≥n final, has completado un proyecto de visi√≥n por computadora de principio a fin.
- **Dominar el Preprocesamiento de Im√°genes:** Entendiste el rol cr√≠tico de la normalizaci√≥n y el **aumento de datos (Data Augmentation)**, una t√©cnica indispensable para cualquier proyecto de visi√≥n.
- **Construir y Entender una CNN:** Ya no es una caja negra. Sabes qu√© son las capas `Conv2D` y `MaxPooling2D` y por qu√© son la base del reconocimiento de im√°genes moderno.
- **Evaluar con Contexto Cl√≠nico:** Reforzaste la idea de que la `accuracy` no lo es todo. Aprendiste a priorizar el **Recall** (sensibilidad) en un problema m√©dico donde los Falsos Negativos son el mayor riesgo.
- **Interpretar Gr√°ficos de Entrenamiento:** Sabes c√≥mo leer las curvas de p√©rdida y precisi√≥n para diagnosticar la salud de tu modelo durante el entrenamiento.
- **Comunicar Resultados Complejos:** Eres capaz de traducir una matriz de confusi√≥n en una recomendaci√≥n estrat√©gica y comprensible para un stakeholder no t√©cnico, como un director de hospital.
# **‚ú® Proyecto | Diagn√≥stico Inteligente: M√°s All√° de la Precisi√≥n en la Predicci√≥n de Enfermedades Card√≠acas**



### **üß† ¬°Bienvenido/a, Data Scientist! üß†**

Hoy no solo vamos a escribir c√≥digo. 

Vamos a resolver un problema real que tiene un impacto directo en la vida de las personas.

## üöÄ El Reto: La Startup "CardioSafe Analytics"

Imagina que eres parte del equipo de Machine Learning de **"CardioSafe Analytics"**, una startup de HealthTech que ha desarrollado un modelo inicial para predecir la probabilidad de que un paciente sufra una enfermedad card√≠aca.

El primer modelo, basado en una regresi√≥n log√≠stica simple, alcanz√≥ una **precisi√≥n (accuracy) del 85%**. El equipo directivo est√° contento, pero el equipo m√©dico est√° preocupado. Nos hacen una pregunta crucial:

> ***"Un 85% de precisi√≥n suena bien, pero... ¬øqu√© significa realmente? ***
>
> ***¬øA cu√°ntos pacientes realmente enfermos estamos mandando a casa dici√©ndoles que est√°n sanos? ***
>
> ***¬øY a cu√°ntos sanos estamos asustando innecesariamente? ***
>
> ***Necesitamos entender la eficiencia real del modelo, no solo un n√∫mero."***

Tu misi√≥n es tomar el control del proyecto. Deber√°s explorar los datos, proponer y entrenar un modelo m√°s robusto, y lo m√°s importante: **evaluar su eficiencia desde una perspectiva cl√≠nica**, explicando a los stakeholders (los m√©dicos y directivos) qu√© significan realmente los resultados.

## üéØ Objetivos de la Pr√°ctica



Al finalizar este reto, ser√°s capaz de:

1. **Realizar un An√°lisis Exploratorio de Datos (EDA)** en un dataset de salud.
2. **Preprocesar los datos** para prepararlos para el entrenamiento de un modelo.
3. **Seleccionar, justificar e implementar un modelo de clasificaci√≥n** robusto como Random Forest.
4. **Evaluar la eficiencia del modelo** utilizando m√©tricas avanzadas m√°s all√° de la precisi√≥n, como la matriz de confusi√≥n, la precisi√≥n (precision) y la sensibilidad (recall).
5. **Interpretar los resultados del modelo** en el contexto de un problema real y comunicar tus hallazgos de forma efectiva.
6. **Identificar los factores m√°s influyentes** en la predicci√≥n de la enfermedad.

## üåê El Dataset: Heart Disease UCI



Usaremos un dataset cl√°sico y muy conocido en la comunidad de Machine Learning, alojado en un repositorio de GitHub para f√°cil acceso. Contiene 14 atributos extra√≠dos de pacientes, como edad, sexo, nivel de colesterol, y si tienen o no una enfermedad card√≠aca (`target`).

**URL del dataset (raw):** `https://raw.githubusercontent.com/dataspelunking/MLwHeartDisease/main/Data/processed.cleveland.data.csv`

## üíª Desarrollo del Proyecto en Google Colab

¬°Es hora de poner manos a la obra! Sigue estos pasos en tu notebook.

### üìò Nota Did√°ctica: Fase 1 - Entendiendo a nuestros "Pacientes" Digitales

Antes de cualquier diagn√≥stico, un buen m√©dico (y un buen Data Scientist) debe conocer a su paciente. Esta primera fase se llama **An√°lisis Exploratorio de Datos (EDA)**. Nuestro objetivo es "escuchar" lo que los datos nos dicen sobre las caracter√≠sticas de los pacientes y la distribuci√≥n de la enfermedad.

#### **Paso 1.1: Configuraci√≥n del Entorno e Importaci√≥n de Librer√≠as**

```python
# üß† Primero, importamos las herramientas que necesitaremos en nuestro laboratorio digital.
# pandas para manejar los datos como si fueran hojas de c√°lculo avanzadas.
# matplotlib y seaborn para crear visualizaciones que nos ayuden a "ver" los datos.
# scikit-learn para los modelos de Machine Learning y las m√©tricas de evaluaci√≥n.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Configuramos un estilo visual agradable para nuestros gr√°ficos.
sns.set_style('whitegrid')
%matplotlib inline
```

#### **Paso 1.2: Carga y Primera Exploraci√≥n de los Datos**

```python
# üß† Cargamos el dataset directamente desde la URL.
# Le asignamos nombres a las columnas seg√∫n la documentaci√≥n del dataset para que sea m√°s legible.

url = 'https://raw.githubusercontent.com/dataspelunking/MLwHeartDisease/main/Data/processed.cleveland.data.csv'
column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']
# El dataset usa '?' para los valores faltantes, se lo indicamos a pandas.
df = pd.read_csv(url, header=None, names=column_names, na_values='?')

# üëÄ Echamos un primer vistazo a los datos para asegurarnos de que se cargaron correctamente.
df.head()
```

-----

```python
# üß† Obtenemos informaci√≥n general del dataset.
# ¬øHay valores nulos? ¬øQu√© tipo de dato tiene cada columna?
# Esto es como la primera ficha m√©dica del paciente.
df.info()
```

### üìò Nota Did√°ctica: Fase 2 - Limpieza y Preparaci√≥n del Quir√≥fano

Los datos del mundo real rara vez son perfectos. A menudo tienen "heridas" (valores faltantes) que debemos curar antes de operar (entrenar el modelo). Esta fase de **limpieza y preprocesamiento** es crucial para la salud de nuestro modelo.

#### **Paso 2.1: Manejo de Datos Faltantes**

```python
# üß† Identificamos cu√°ntos valores nulos hay por columna.
df.isnull().sum()
```

-------

```python
# üß† Dado que son pocos los valores nulos, una estrategia simple y efectiva es rellenarlos
# con la mediana de su respectiva columna. La mediana es m√°s robusta a valores at√≠picos que la media.
# Es una "cirug√≠a" menor y segura.

df['ca'].fillna(df['ca'].median(), inplace=True)
df['thal'].fillna(df['thal'].median(), inplace=True)

# Verificamos que ya no hay valores nulos. ¬°El paciente est√° limpio!
print("Valores nulos despu√©s de la limpieza:")
print(df.isnull().sum())
```

#### **Paso 2.2: Visualizando la Distribuci√≥n de la Enfermedad**

```python
# üìä ¬øCu√°ntos pacientes en nuestro dataset est√°n enfermos vs. sanos?
# La columna 'target' nos lo dice: 0 = No hay enfermedad, >0 = Hay enfermedad.
# Para simplificar, convertiremos todos los valores > 0 a 1.

df['target'] = (df['target'] > 0).astype(int)

# Ahora visualizamos la distribuci√≥n.
plt.figure(figsize=(8, 6))
sns.countplot(x='target', data=df, palette='viridis')
plt.title('Distribuci√≥n de Pacientes con y sin Enfermedad Card√≠aca')
plt.xticks([0, 1], ['Sanos (0)', 'Enfermos (1)'])
plt.ylabel('Cantidad de Pacientes')
plt.show()

print(df['target'].value_counts(normalize=True))
```

> **Interpretaci√≥n:** Vemos que el dataset est√° razonablemente balanceado. No hay una clase abrumadoramente mayoritaria, lo cual es bueno para el entrenamiento del modelo.

#### **Paso 2.3: Visualizando la Correlaci√≥n entre Variables**

```python
# üìä Una matriz de correlaci√≥n nos ayuda a entender c√≥mo se relacionan las variables entre s√≠.
# ¬øQu√© factores est√°n m√°s asociados con la enfermedad card√≠aca?
# Un mapa de calor es la mejor forma de visualizar esto.

plt.figure(figsize=(14, 10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Mapa de Calor de Correlaci√≥n de Variables')
plt.show()
```

> **Interpretaci√≥n:** Observa la √∫ltima fila (`target`). Las variables con colores m√°s intensos (rojo o azul) son las que tienen una mayor correlaci√≥n (positiva o negativa) con la presencia de una enfermedad card√≠aca. Por ejemplo, `cp` (tipo de dolor de pecho) y `thalach` (frecuencia card√≠aca m√°xima) tienen una correlaci√≥n positiva fuerte, mientras que `exang` (angina inducida por ejercicio) y `oldpeak` tienen una correlaci√≥n negativa.

### üìò Nota Did√°ctica: Fase 3 - Construyendo y Evaluando Nuestro Nuevo Modelo

Ahora viene el n√∫cleo de nuestra misi√≥n. Separaremos los datos para entrenar y probar nuestro modelo. Elegiremos un **Random Forest** en lugar de la regresi√≥n log√≠stica inicial.

> **¬øPor qu√© un Random Forest?**
>
> 1. **Es m√°s robusto:** Es un "comit√© de expertos" (m√∫ltiples √°rboles de decisi√≥n) que votan por el resultado final. Esto reduce el riesgo de que un solo "experto" se equivoque (overfitting).
> 2. **Maneja relaciones complejas:** No asume que la relaci√≥n entre las variables es lineal, algo muy com√∫n en biolog√≠a.
> 3. **Nos da "Feature Importance":** Nos puede decir qu√© variables considera m√°s importantes para hacer su diagn√≥stico, ¬°informaci√≥n valios√≠sima para los m√©dicos!

#### **Paso 3.1: Separaci√≥n de Datos en Entrenamiento y Prueba**

```python
# üß† Separamos nuestro dataset en dos:
# X: Las caracter√≠sticas del paciente (las variables predictoras).
# y: El diagn√≥stico que queremos predecir (la variable objetivo, 'target').

X = df.drop('target', axis=1)
y = df['target']

# Dividimos los datos. Usaremos el 80% para entrenar al modelo y el 20% para probar
# su eficiencia de forma imparcial. `random_state` asegura que la divisi√≥n sea siempre la misma.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Tama√±o del set de entrenamiento: {X_train.shape[0]} pacientes")
print(f"Tama√±o del set de prueba: {X_test.shape[0]} pacientes")
```

#### **Paso 3.2: Entrenamiento del Modelo Random Forest**

```python
# üß† Creamos una instancia del clasificador Random Forest.
# n_estimators=100 significa que nuestro "comit√©" tendr√° 100 √°rboles de decisi√≥n.
# random_state=42 para reproducibilidad.

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# ¬°El momento de la verdad! Entrenamos el modelo con los datos de entrenamiento.
# El modelo est√° "estudiando" los casos de los pacientes para aprender los patrones.
rf_model.fit(X_train, y_train)
```

#### **Paso 3.3: Evaluaci√≥n de la Eficiencia del Modelo**

```python
# üß† Ahora que el modelo ha sido entrenado, lo probamos con datos que nunca ha visto antes.
y_pred = rf_model.predict(X_test)

# 1. La m√©trica b√°sica: Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"‚úÖ Accuracy del Modelo Random Forest: {accuracy:.2f}")
print("-" * 50)

# 2. El reporte completo para los m√©dicos: Classification Report
# Aqu√≠ vemos la precisi√≥n (precision), sensibilidad (recall) y F1-score.
print("üìä Reporte de Clasificaci√≥n:")
print(classification_report(y_test, y_pred, target_names=['Sano (Clase 0)', 'Enfermo (Clase 1)']))
print("-" * 50)

# 3. La herramienta de diagn√≥stico clave: La Matriz de Confusi√≥n
print("üîç Matriz de Confusi√≥n:")
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicci√≥n Sano', 'Predicci√≥n Enfermo'],
            yticklabels=['Real Sano', 'Real Enfermo'])
plt.title('Matriz de Confusi√≥n')
plt.ylabel('Valor Real')
plt.xlabel('Valor Predicho')
plt.show()
```

### üìò Nota Did√°ctica: Fase 4 - Comunicando los Resultados a "CardioSafe"

¬°Excelente trabajo! Nuestro modelo parece tener una accuracy similar al anterior, pero ahora tenemos herramientas mucho m√°s poderosas para responder a las preocupaciones del equipo m√©dico.

> **Pensemos como m√©dicos al leer la Matriz de Confusi√≥n:**
>
> - **Verdaderos Positivos (VP):** 24. Pacientes enfermos que diagnosticamos correctamente como enfermos. ¬°Genial!
> - **Verdaderos Negativos (VN):** 29. Pacientes sanos que diagnosticamos correctamente como sanos. ¬°Perfecto!
> - **Falsos Positivos (FP):** 2. Pacientes sanos que diagnosticamos err√≥neamente como enfermos. Esto genera ansiedad y costos de pruebas innecesarias, pero no es fatal.
> - **Falsos Negativos (FN):** 6. **¬°ESTE ES EL N√öMERO CR√çTICO!** Son pacientes enfermos que mandamos a casa dici√©ndoles que estaban sanos. Es el peor error posible en este contexto.

El **Recall** (o sensibilidad) para la clase "Enfermo" nos dice que detectamos al 80% de los pacientes que realmente ten√≠an la enfermedad (`24 / (24 + 6)`). Nuestro objetivo como equipo ser√≠a reducir esos 6 Falsos Negativos, incluso si eso significa aumentar un poco los Falsos Positivos.

#### **Paso 4.1: Identificando los Factores Clave (Feature Importance)**

```python
# üß† Una de las grandes ventajas del Random Forest.
# Podemos preguntarle al modelo: "¬øQu√© factores fueron los m√°s importantes para tomar tus decisiones?"

importances = rf_model.feature_importances_
feature_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
feature_df = feature_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=feature_df, palette='viridis')
plt.title('Importancia de cada Caracter√≠stica en la Predicci√≥n')
plt.xlabel('Importancia')
plt.ylabel('Caracter√≠stica')
plt.show()
```

> **Conclusi√≥n para los Stakeholders:** *"Equipo, nuestro nuevo modelo no solo mantiene una buena precisi√≥n, sino que ahora podemos ver que los factores m√°s determinantes para el diagn√≥stico son el **tipo de dolor de pecho (cp)**, la **frecuencia card√≠aca m√°xima alcanzada (thalach)** y la **depresi√≥n del segmento ST (oldpeak)**. *
>
> *M√°s importante a√∫n, hemos identificado que nuestro principal desaf√≠o son los **Falsos Negativos**. Propongo que la siguiente fase del proyecto se centre en t√©cnicas para minimizar este error espec√≠fico, ya que tiene el mayor impacto cl√≠nico."*

## ‚úÖ ¬øQu√© has aprendido en esta misi√≥n?

Si has llegado hasta aqu√≠, ¬°felicidades! No solo has construido un modelo de Machine Learning, has actuado como un verdadero Data Scientist en un proyecto con impacto real. Concretamente, has logrado:

- **Habilidad T√©cnica:** Implementaste un flujo de trabajo completo de Machine Learning: carga, limpieza, visualizaci√≥n, entrenamiento y evaluaci√≥n.
- **Pensamiento Cr√≠tico:** Comprendiste por qu√© la **accuracy no es suficiente** y aprendiste a usar e interpretar la **matriz de confusi√≥n** y el **reporte de clasificaci√≥n** para evaluar la eficiencia real de un modelo.
- **Justificaci√≥n de Modelos:** Entendiste las ventajas de un modelo como **Random Forest** sobre otros m√°s simples, especialmente su capacidad para darnos la importancia de las caracter√≠sticas.
- **Comunicaci√≥n Efectiva:** Aprendiste a "traducir" m√©tricas t√©cnicas (como Falsos Negativos) en **riesgos y conclusiones de negocio** (impacto cl√≠nico) para una audiencia no especializada.
- **Visi√≥n de Proyecto:** Te posicionaste no como alguien que solo ejecuta c√≥digo, sino como un **solucionador de problemas** que analiza resultados y propone los siguientes pasos estrat√©gicos.
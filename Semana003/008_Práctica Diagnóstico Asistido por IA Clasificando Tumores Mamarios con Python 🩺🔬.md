# **Pr√°ctica:** **"Diagn√≥stico Asistido por IA: Clasificando Tumores Mamarios con Python ü©∫üî¨"**

**Objetivo:** Construir y evaluar dos modelos de aprendizaje supervisado para clasificar tumores mamarios como benignos o malignos, bas√°ndose en caracter√≠sticas extra√≠das de im√°genes digitalizadas de aspirados con aguja fina (FNA).

**Herramientas:** Visual Studio Code o Google Colab con Python.

**Dataset:** Breast Cancer Wisconsin (Diagnostic)

- **URL para descargar (CSV):** [https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data](https://www.google.com/url?sa=E&q=https%3A%2F%2Farchive.ics.uci.edu%2Fml%2Fmachine-learning-databases%2Fbreast-cancer-wisconsin%2Fwdbc.data)
- **Informaci√≥n del dataset (nombres de columnas, etc.):** [https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names](https://www.google.com/url?sa=E&q=https%3A%2F%2Farchive.ics.uci.edu%2Fml%2Fmachine-learning-databases%2Fbreast-cancer-wisconsin%2Fwdbc.names)

## **PASO A PASO DETALLADO üìù**

### **Paso 0: Configuraci√≥n del Entorno y Librer√≠as üõ†Ô∏è**

```python
# Importaci√≥n de librer√≠as necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score

# Configuraciones para visualizaciones (opcional, pero recomendado)
plt.style.use('seaborn-v0_8-whitegrid') # Estilo de gr√°ficos agradable
sns.set_palette('pastel') # Paleta de colores
print("Librer√≠as importadas exitosamente! üéâ")
```

### **Paso 1: Carga y Exploraci√≥n Inicial de los Datos üìä**

Vamos a cargar los datos desde la URL de UCI. El archivo wdbc.data no tiene encabezados, as√≠ que se los a√±adiremos seg√∫n el archivo wdbc.names.

```python
# URL del dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"

# Nombres de las columnas (seg√∫n wdbc.names)
# La primera columna es ID (que descartaremos), la segunda es Diagnosis (M=malignant, B=benign)
# Las siguientes 30 son las caracter√≠sticas num√©ricas.
column_names = ['id', 'diagnosis'] + [f'feature_{i}' for i in range(1, 31)]

# Cargar el dataset
df = pd.read_csv(url, header=None, names=column_names)

print("Dataset cargado! primeras 5 filas: ")
print(df.head())
print("\nInformaci√≥n general del DataFrame:")
df.info()
print("\nEstad√≠sticas descriptivas:")
print(df.describe())
print("\nConteo de valores nulos por columna:")
print(df.isnull().sum())
```

#### **Observaciones de la Exploraci√≥n Inicial:**

- Vemos que la columna id no ser√° √∫til para la predicci√≥n, as√≠ que la eliminaremos.
- La columna diagnosis es nuestro objetivo (target) y es categ√≥rica ('M' o 'B'). Necesitaremos convertirla a num√©rica.
- Las otras 30 columnas (feature_1 a feature_30) son las caracter√≠sticas predictoras. Todas parecen ser num√©ricas.
- No hay valores nulos, ¬°lo cual es genial! üëç

### **Paso 2: Limpieza y Preprocesamiento de Datos üßπ‚ú®**

1. **Eliminar columna ID:**
2. **Codificar la variable objetivo diagnosis:** 'M' (maligno) a 1 y 'B' (benigno) a 0.
3. **Separar caracter√≠sticas (X) y objetivo (y).**
4. **Escalar las caracter√≠sticas:** Muchos algoritmos (como Regresi√≥n Log√≠stica y SVM) funcionan mejor o son m√°s estables cuando las caracter√≠sticas num√©ricas est√°n en una escala similar. Usaremos StandardScaler.

```python
# 1. Eliminar columna ID
df = df.drop('id', axis=1)
print("\nColumna 'id' eliminada.")

# 2. Codificar la variable objetivo 'diagnosis'
# Usaremos LabelEncoder, pero tambi√©n se puede hacer con map: df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0})
le = LabelEncoder()
df['diagnosis'] = le.fit_transform(df['diagnosis'])
# M (maligno) se mapea a 1, B (benigno) se mapea a 0. Guardamos las clases para referencia.
# print(f"Clases aprendidas por LabelEncoder: {le.classes_} -> {le.transform(le.classes_)}")
print(f"\nVariable 'diagnosis' codificada: (M={le.transform(['M'])[0]}, B={le.transform(['B'])[0]})")
print("Primeras filas con 'diagnosis' codificada:")
print(df.head())

# 3. Separar caracter√≠sticas (X) y objetivo (y)
X = df.drop('diagnosis', axis=1)
y = df['diagnosis']
print(f"\nDimensiones de X: {X.shape}")
print(f"Dimensiones de y: {y.shape}")

# 4. Escalar las caracter√≠sticas
# Es importante escalar DESPU√âS de dividir en train/test para evitar data leakage del test set al training set.
# Sin embargo, para la exploraci√≥n inicial (como el heatmap de correlaci√≥n) podemos usar X sin escalar o escalarlo completo temporalmente.
# Aqu√≠, escalaremos despu√©s de la divisi√≥n.

print("\nPreprocesamiento b√°sico completado! üßº")
```

### **Paso 3: Divisi√≥n de los Datos en Conjuntos de Entrenamiento y Prueba**

Dividiremos los datos para poder entrenar el modelo con una porci√≥n y evaluarlo con otra porci√≥n que no ha visto antes.

```python
# Dividir los datos: 70% para entrenamiento, 30% para prueba
# random_state asegura reproducibilidad. stratify=y asegura que la proporci√≥n de clases sea similar en train y test.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print(f"Tama√±o de X_train: {X_train.shape}, X_test: {X_test.shape}")
print(f"Tama√±o de y_train: {y_train.shape}, y_test: {y_test.shape}")
print(f"Proporci√≥n de clases en y_train:\n{y_train.value_counts(normalize=True)}")
print(f"Proporci√≥n de clases en y_test:\n{y_test.value_counts(normalize=True)}")

# Ahora s√≠, escalamos las caracter√≠sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) # Ajusta el scaler en train y lo transforma
X_test_scaled = scaler.transform(X_test)     # Solo transforma el test con el scaler ajustado en train

# Convertir de nuevo a DataFrames para mantener los nombres de las columnas (opcional, pero √∫til para inspecci√≥n)
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)

print("\nDatos divididos y escalados! Listos para el modelado. üöÇ")
```

### **Paso 4: Selecci√≥n, Entrenamiento y Evaluaci√≥n del Modelo 1 - Regresi√≥n Log√≠stica üìà**

#### **¬øPor qu√© Regresi√≥n Log√≠stica?**

- Es un modelo lineal simple, r√°pido de entrenar e interpretable.
- Proporciona probabilidades, lo cual puede ser √∫til.
- Es un buen modelo base para problemas de clasificaci√≥n binaria.
- Funciona bien cuando las caracter√≠sticas est√°n escaladas.

```python
print("\n--- Modelo 1: Regresi√≥n Log√≠stica ---")
# Instanciar el modelo
log_reg = LogisticRegression(random_state=42, solver='liblinear') # liblinear es bueno para datasets peque√±os

# Entrenar el modelo
log_reg.fit(X_train_scaled, y_train)
print("Modelo de Regresi√≥n Log√≠stica entrenado. ‚úÖ")

# Realizar predicciones en el conjunto de prueba
y_pred_log_reg = log_reg.predict(X_test_scaled)
y_pred_proba_log_reg = log_reg.predict_proba(X_test_scaled)[:, 1] # Probabilidades para la clase positiva (1)

# Evaluar el modelo
accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)
class_report_log_reg = classification_report(y_test, y_pred_log_reg)

print(f"\nAccuracy (Regresi√≥n Log√≠stica): {accuracy_log_reg:.4f}")
print(f"AUC-ROC (Regresi√≥n Log√≠stica): {roc_auc_score(y_test, y_pred_proba_log_reg):.4f}")
print("\nMatriz de Confusi√≥n (Regresi√≥n Log√≠stica):")
# Usamos un heatmap para la matriz de confusi√≥n para que sea m√°s visual
# Clases: 0 (Benigno), 1 (Maligno)
# Mapeo original: M=1, B=0. le.classes_ nos da ['B', 'M'] que mapean a [0, 1]
class_names = le.classes_ # ['B', 'M']
sns.heatmap(conf_matrix_log_reg, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicci√≥n')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusi√≥n - Regresi√≥n Log√≠stica')
plt.show()

print("\nInforme de Clasificaci√≥n (Regresi√≥n Log√≠stica):")
print(class_report_log_reg)
```

#### **Interpretaci√≥n de la Regresi√≥n Log√≠stica:**

- La **Accuracy** nos da el porcentaje total de predicciones correctas.
- La **Matriz de Confusi√≥n** nos muestra:
  - Verdaderos Negativos (TN): Casos Benignos predichos correctamente como Benignos.
  - Falsos Positivos (FP): Casos Benignos predichos incorrectamente como Malignos (Error Tipo I).
  - Falsos Negativos (FN): Casos Malignos predichos incorrectamente como Benignos (Error Tipo II - ¬°muy importante en diagn√≥stico!).
  - Verdaderos Positivos (TP): Casos Malignos predichos correctamente como Malignos.
- El **Informe de Clasificaci√≥n** detalla Precision, Recall y F1-score para cada clase.
  - **Precision (para Maligno):** De todos los que predijo como Malignos, ¬øcu√°ntos realmente lo eran? TP / (TP + FP)
  - **Recall (Sensibilidad, para Maligno):** De todos los que realmente eran Malignos, ¬øcu√°ntos detect√≥? TP / (TP + FN)
  - **F1-score:** Media arm√≥nica de Precision y Recall.

#### **Paso 5: Selecci√≥n, Entrenamiento y Evaluaci√≥n del Modelo 2 - Random Forest Classifier üå≥üå≥**

**¬øPor qu√© Random Forest?**

- Es un m√©todo ensemble (basado en √°rboles de decisi√≥n) que generalmente ofrece alta precisi√≥n.
- Es robusto al sobreajuste (overfitting) en comparaci√≥n con un solo √°rbol de decisi√≥n.
- Puede capturar relaciones no lineales en los datos.
- No requiere que las caracter√≠sticas est√©n escaladas (aunque ya las tenemos escaladas, no le perjudica).

```python
print("\n--- Modelo 2: Random Forest Classifier ---")
# Instanciar el modelo
# n_estimators: n√∫mero de √°rboles en el bosque. random_state para reproducibilidad.
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
# class_weight='balanced' puede ayudar si hay desbalanceo, aunque aqu√≠ es leve.

# Entrenar el modelo
rf_clf.fit(X_train_scaled, y_train) # Podr√≠amos usar X_train sin escalar, pero con escalado est√° bien tambi√©n
print("Modelo Random Forest entrenado. ‚úÖ")

# Realizar predicciones en el conjunto de prueba
y_pred_rf = rf_clf.predict(X_test_scaled)
y_pred_proba_rf = rf_clf.predict_proba(X_test_scaled)[:, 1] # Probabilidades para la clase positiva (1)

# Evaluar el modelo
accuracy_rf = accuracy_score(y_test, y_pred_rf)
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
class_report_rf = classification_report(y_test, y_pred_rf)

print(f"\nAccuracy (Random Forest): {accuracy_rf:.4f}")
print(f"AUC-ROC (Random Forest): {roc_auc_score(y_test, y_pred_proba_rf):.4f}")
print("\nMatriz de Confusi√≥n (Random Forest):")
sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Greens',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicci√≥n')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusi√≥n - Random Forest')
plt.show()

print("\nInforme de Clasificaci√≥n (Random Forest):")
print(class_report_rf)
```

#### **Paso 6: Visualizaciones Adicionales üñºÔ∏è**

1. **Gr√°fico 1: Heatmap de Correlaci√≥n de Caracter√≠sticas**

   Esto nos ayuda a entender las relaciones lineales entre las caracter√≠sticas. Lo haremos sobre el X original (antes de escalar y dividir) para tener una visi√≥n global.

```
print("\n--- Gr√°fico 1: Heatmap de Correlaci√≥n de Caracter√≠sticas ---")
plt.figure(figsize=(18, 15)) # Ajustar tama√±o para mejor visualizaci√≥n
# Usaremos X (features originales) para este heatmap
correlation_matrix = X.corr()
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=".1f", linewidths=.5)
# annot=True puede ser muy denso con 30 features, por eso False. fmt=".1f" es para formato de anotaci√≥n.
plt.title('Heatmap de Correlaci√≥n de Caracter√≠sticas del Dataset Breast Cancer')
plt.show()
```

#### **Interpretaci√≥n del Heatmap:**

- Colores rojos intensos indican correlaci√≥n positiva fuerte.
- Colores azules intensos indican correlaci√≥n negativa fuerte.
- Colores cercanos al blanco indican poca o ninguna correlaci√≥n lineal.
- Podemos observar grupos de caracter√≠sticas altamente correlacionadas (multicolinealidad), lo cual es com√∫n en este dataset ya que muchas caracter√≠sticas son "mean", "stderr" y "worst" (peor o mayor) de las mismas mediciones base (ej. radius_mean, radius_stderr, radius_worst).

1. **Gr√°fico 2: Curvas ROC Comparativas**
   La curva ROC (Receiver Operating Characteristic) es excelente para comparar el rendimiento de clasificadores binarios, especialmente cuando las clases est√°n desbalanceadas o los costos de los errores son diferentes. Grafica la Tasa de Verdaderos Positivos (Recall/Sensibilidad) contra la Tasa de Falsos Positivos.

```python
print("\n--- Gr√°fico 2: Curvas ROC Comparativas ---")
# Calcular FPR, TPR para Regresi√≥n Log√≠stica
fpr_log_reg, tpr_log_reg, thresholds_log_reg = roc_curve(y_test, y_pred_proba_log_reg)
auc_log_reg = roc_auc_score(y_test, y_pred_proba_log_reg)

# Calcular FPR, TPR para Random Forest
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_proba_rf)
auc_rf = roc_auc_score(y_test, y_pred_proba_rf)

plt.figure(figsize=(10, 7))
plt.plot(fpr_log_reg, tpr_log_reg, label=f'Regresi√≥n Log√≠stica (AUC = {auc_log_reg:.3f})', color='blue', linestyle='--')
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})', color='green')
plt.plot([0, 1], [0, 1], color='red', linestyle=':', label='Clasificador Aleatorio (AUC = 0.500)') # L√≠nea de no discriminaci√≥n
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad/Recall)')
plt.title('Comparaci√≥n de Curvas ROC')
plt.legend()
plt.grid(True)
plt.show()
```

**Interpretaci√≥n de la Curva ROC:**

- Un clasificador ideal tendr√≠a una curva que llega hasta la esquina superior izquierda (TPR=1, FPR=0).
- El √Årea Bajo la Curva (AUC) resume el rendimiento del clasificador. Un AUC de 1 es perfecto, 0.5 es aleatorio.
- Cuanto m√°s "arriba y a la izquierda" est√© la curva, mejor es el clasificador.
- Esta gr√°fica nos permite ver visualmente qu√© modelo tiene un mejor compromiso entre sensibilidad y especificidad en diferentes umbrales de decisi√≥n.

### **Paso 7: Conclusi√≥n y Discusi√≥n Final üßë‚Äç‚öñÔ∏è**

```
print("\n--- Conclusiones de la Pr√°ctica --- üèÅ")

print(f"Resultados Regresi√≥n Log√≠stica: Accuracy = {accuracy_log_reg:.4f}, AUC = {auc_log_reg:.4f}")
print(f"Resultados Random Forest:       Accuracy = {accuracy_rf:.4f}, AUC = {auc_rf:.4f}")

print("\nComparaci√≥n:")
if accuracy_rf > accuracy_log_reg and auc_rf > auc_log_reg:
    print("üèÜ Random Forest mostr√≥ un mejor rendimiento general (Accuracy y AUC).")
elif accuracy_log_reg > accuracy_rf and auc_log_reg > auc_rf:
    print("üèÜ Regresi√≥n Log√≠stica mostr√≥ un mejor rendimiento general (Accuracy y AUC).")
else:
    print("üìä Los modelos tuvieron rendimientos mixtos o muy similares en Accuracy y AUC. Revisar m√©tricas espec√≠ficas.")

print("\nDiscusi√≥n Detallada:")
print("Ambos modelos, Regresi√≥n Log√≠stica y Random Forest, lograron un buen rendimiento en la clasificaci√≥n de tumores mamarios.")
print("1.  **Regresi√≥n Log√≠stica:** Si bien es un modelo m√°s simple, obtuvo una alta accuracy y AUC, demostrando ser efectivo para este problema. Su interpretabilidad (a trav√©s de los coeficientes, no explorados aqu√≠) podr√≠a ser una ventaja en contextos m√©dicos.")
print("2.  **Random Forest:** Generalmente, se espera que Random Forest supere o iguale a modelos m√°s simples. En este caso, si el AUC o la accuracy son ligeramente superiores, podr√≠a ser la elecci√≥n preferida si la m√°xima capacidad predictiva es el objetivo principal, incluso a costa de una menor interpretabilidad directa en comparaci√≥n con la Regresi√≥n Log√≠stica.")
print("\nConsideraciones Cruciales para este Caso (M√©dico):")
print("   - **Falsos Negativos (FN):** En un diagn√≥stico de c√°ncer, un Falso Negativo (predecir 'Benigno' cuando es 'Maligno') es t√≠picamente el error m√°s costoso. Debemos prestar especial atenci√≥n al Recall de la clase 'Maligno'.")
print("     - Recall para Maligno (Reg. Log√≠stica):", class_report_log_reg.splitlines()[3].split()[3]) # Extrae el recall de la clase 1
print("     - Recall para Maligno (Random Forest):", class_report_rf.splitlines()[3].split()[3])

print("\nPosibles Pr√≥ximos Pasos:")
print("   - **Ajuste de Hiperpar√°metros:** Usar t√©cnicas como GridSearchCV o RandomizedSearchCV para encontrar los mejores hiperpar√°metros para cada modelo.")
print("   - **Ingenier√≠a de Caracter√≠sticas:** Aunque este dataset es bastante bueno, en otros casos se podr√≠an crear nuevas caracter√≠sticas.")
print("   - **Explorar otros modelos:** Probar SVM, Gradient Boosting (XGBoost, LightGBM), Redes Neuronales.")
print("   - **Validaci√≥n Cruzada m√°s robusta:** Para una estimaci√≥n m√°s fiable del rendimiento.")
print("   - **An√°lisis de Importancia de Caracter√≠sticas (para Random Forest):** Ver qu√© caracter√≠sticas contribuyen m√°s a la predicci√≥n.")

print("\n¬°Pr√°ctica completada! üéâ Has construido y evaluado dos modelos de ML para un problema de clasificaci√≥n real.")
```
# **‚ö° Pr√°ctica e-learning: Clasificaci√≥n con Gradient Boosting**

## üéØ Objetivos

- Comprender c√≥mo funciona el algoritmo de boosting mediante `GradientBoostingClassifier`.
- Aplicarlo a un dataset real y de acceso libre.
- Evaluar el rendimiento del modelo.
- Visualizar e interpretar las variables m√°s importantes.

## üß∞ Paso 1: Importar Librer√≠as

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
```

## üì• Paso 2: Cargar Dataset desde Repositorio Abierto

Usamos el dataset de enfermedades card√≠acas, disponible p√∫blicamente en GitHub:

üîó URL:
 https://raw.githubusercontent.com/ybifoundation/Dataset/main/Heart.csv

```python
# Cargar datos desde GitHub
url = "https://raw.githubusercontent.com/ybifoundation/Dataset/main/Heart.csv"
df = pd.read_csv(url)

# Mostrar las primeras filas
df.head()
```

## ‚úÇÔ∏è Paso 3: Preparaci√≥n de Datos

```python
# Separar caracter√≠sticas y variable objetivo
X = df.drop(columns='HeartDisease')
y = df['HeartDisease']

# Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

## ‚öôÔ∏è Paso 4: Entrenar el Modelo Gradient Boosting

```python
# Crear y ajustar el modelo
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train, y_train)
```

## üìä Paso 5: Evaluar el Modelo

```python
# Predicci√≥n
y_pred = gb_model.predict(X_test)

# M√©tricas
print("Exactitud:", accuracy_score(y_test, y_pred))
print("\nReporte de Clasificaci√≥n:")
print(classification_report(y_test, y_pred))
```

## üìà Paso 6: Visualizar Resultados

### a) Matriz de Confusi√≥n

```python
# Visualizaci√≥n de matriz
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Greens')
plt.title("Matriz de Confusi√≥n - Gradient Boosting")
plt.xlabel("Predicci√≥n")
plt.ylabel("Valor Real")
plt.show()
```

### b) Importancia de Variables

```python
# Importancia de caracter√≠sticas
importances = gb_model.feature_importances_
features = X.columns

plt.figure(figsize=(10,6))
sns.barplot(x=importances, y=features)
plt.title("Importancia de Caracter√≠sticas - Gradient Boosting")
plt.xlabel("Importancia Relativa")
plt.ylabel("Variables")
plt.grid(True)
plt.show()
```

## ‚úÖ Conclusi√≥n

- Gradient Boosting mejora modelos secuencialmente, corrigiendo errores del modelo anterior.
- Es poderoso para tareas de clasificaci√≥n compleja.
- La visualizaci√≥n ayuda a identificar qu√© variables m√°s contribuyen al resultado.
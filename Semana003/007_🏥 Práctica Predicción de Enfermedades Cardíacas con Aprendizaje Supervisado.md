## üè• Pr√°ctica: Predicci√≥n de Enfermedades Card√≠acas con Aprendizaje Supervisado

### üéØ Objetivo

Desarrollar un modelo de aprendizaje supervisado para predecir la presencia de enfermedades card√≠acas en pacientes, utilizando caracter√≠sticas cl√≠nicas y demogr√°ficas.

------

### üì• Paso 1: Importar Librer√≠as Necesarias

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
```

### üìö Paso 2: Cargar el Conjunto de Datos

Utilizaremos el conjunto de datos de enfermedades card√≠acas disponible en el UCI Machine Learning Repository.

üîó URL de descarga: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data

```python
# Definir nombres de columnas seg√∫n la documentaci√≥n
column_names = [
    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',
    'restecg', 'thalach', 'exang', 'oldpeak', 'slope',
    'ca', 'thal', 'target'
]

# Cargar los datos
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'
df = pd.read_csv(url, names=column_names)
```

### üßπ Paso 3: Exploraci√≥n y Limpieza de Datos

```python
# Reemplazar los signos de interrogaci√≥n por NaN
df.replace('?', np.nan, inplace=True)

# Convertir columnas a tipo num√©rico
for col in ['ca', 'thal']:
    df[col] = pd.to_numeric(df[col])

# Eliminar filas con valores faltantes
df.dropna(inplace=True)

# Convertir la columna objetivo a binaria: 0 (sin enfermedad), 1 (con enfermedad)
df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)

# Mostrar informaci√≥n general
df.info()
```

### üìä Paso 4: An√°lisis Exploratorio de Datos

```python
# Distribuci√≥n de la variable objetivo
sns.countplot(x='target', data=df)
plt.title('Distribuci√≥n de la Variable Objetivo')
plt.xlabel('Presencia de Enfermedad Card√≠aca')
plt.ylabel('Cantidad')
plt.show()

# Correlaci√≥n entre variables
plt.figure(figsize=(12,10))
sns.heatmap(df.corr(), annot=True, fmt=".2f")
plt.title('Matriz de Correlaci√≥n')
plt.show()
```

### ‚úÇÔ∏è Paso 5: Divisi√≥n de los Datos

```python
# Separar caracter√≠sticas y variable objetivo
X = df.drop('target', axis=1)
y = df['target']

# Dividir en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Escalar las caracter√≠sticas
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

### ü§ñ Paso 6: Selecci√≥n y Entrenamiento de Modelos

#### Modelo 1: Regresi√≥n Log√≠stica

```python
# Crear y entrenar el modelo
log_model = LogisticRegression()
log_model.fit(X_train, y_train)

# Realizar predicciones
y_pred_log = log_model.predict(X_test)
```

#### Modelo 2: Bosque Aleatorio (Random Forest)

```python
# Crear y entrenar el modelo
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Realizar predicciones
y_pred_rf = rf_model.predict(X_test)
```

### üìà Paso 7: Evaluaci√≥n de Modelos

#### Regresi√≥n Log√≠stica

```python
print("Regresi√≥n Log√≠stica:")
print("Exactitud:", accuracy_score(y_test, y_pred_log))
print("Reporte de Clasificaci√≥n:\n", classification_report(y_test, y_pred_log))
```

#### Bosque Aleatorio

```python
print("Bosque Aleatorio:")
print("Exactitud:", accuracy_score(y_test, y_pred_rf))
print("Reporte de Clasificaci√≥n:\n", classification_report(y_test, y_pred_rf))
```

### üìä Paso 8: Visualizaci√≥n de Resultados

#### a) Matriz de Confusi√≥n

```python
# Matriz de confusi√≥n para Bosque Aleatorio
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confusi√≥n - Bosque Aleatorio')
plt.xlabel('Predicci√≥n')
plt.ylabel('Valor Real')
plt.show()
```

#### b) Importancia de Caracter√≠sticas

```python
# Importancia de caracter√≠sticas en Bosque Aleatorio
importances = rf_model.feature_importances_
features = X.columns
indices = np.argsort(importances)

plt.figure(figsize=(10,6))
plt.title('Importancia de Caracter√≠sticas')
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Importancia Relativa')
plt.show()
```

### ‚úÖ Conclusi√≥n

En esta pr√°ctica, hemos desarrollado y evaluado dos modelos de aprendizaje supervisado para predecir la presencia de enfermedades card√≠acas. Ambos modelos han mostrado un desempe√±o razonable, siendo el Bosque Aleatorio ligeramente superior en t√©rminos de exactitud. 

La visualizaci√≥n de la importancia de caracter√≠sticas nos ha permitido identificar las variables m√°s influyentes en la predicci√≥n, lo cual es valioso para la interpretaci√≥n cl√≠nica y la toma de decisiones.
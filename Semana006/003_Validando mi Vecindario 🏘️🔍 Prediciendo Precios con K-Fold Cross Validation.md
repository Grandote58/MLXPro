# **Validando mi Vecindario ğŸ˜ï¸ğŸ”: Prediciendo Precios con K-Fold Cross Validation**

### ğŸ¯ **Objetivo**

Aprender a implementar **K-Fold Cross Validation** para evaluar el desempeÃ±o de un modelo de regresiÃ³n lineal sobre el dataset **California Housing**, observando los resultados en cada fold para analizar su estabilidad y capacidad de generalizaciÃ³n.

### ğŸ“¦ **Dataset**

Se usarÃ¡ el dataset real de California Housing.

ğŸ”— URL oficial:
 https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html

### ğŸ§ª **Paso a paso en Google Colab**

#### ğŸ”¹ Paso 1: Importar librerÃ­as ğŸ§°

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
```

#### ğŸ”¹ Paso 2: Cargar el dataset ğŸ¡

```python
# Cargar datos de California Housing
data = fetch_california_housing(as_frame=True)
X = data.data
y = data.target

# Mostrar estructura del dataset
X.head()
```

#### ğŸ”¹ Paso 3: Escalar las caracterÃ­sticas âš–ï¸

```python
# Escalar los datos para mejorar el rendimiento del modelo
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### ğŸ”¹ Paso 4: Configurar K-Fold y modelo ğŸ¤–

```python
# Crear modelo de regresiÃ³n
modelo = LinearRegression()

# Configurar validaciÃ³n cruzada con K=5
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
```

#### ğŸ”¹ Paso 5: Ejecutar ValidaciÃ³n Cruzada y evaluar ğŸ”„ğŸ“

```python
# Validar usando RÂ² como mÃ©trica
scores = cross_val_score(modelo, X_scaled, y, cv=kfold, scoring='r2')

# Mostrar resultados por fold
for i, score in enumerate(scores, 1):
    print(f"ğŸ“‚ Fold {i} - RÂ²: {score:.4f}")

# Promedio y desviaciÃ³n estÃ¡ndar
print(f"\nâœ… Promedio de RÂ²: {scores.mean():.4f}")
print(f"ğŸ“‰ DesviaciÃ³n estÃ¡ndar de RÂ²: {scores.std():.4f}")
```

#### ğŸ”¹ Paso 6: Visualizar los resultados por Fold ğŸ“Š

```python
# VisualizaciÃ³n de los puntajes
plt.figure(figsize=(8, 5))
plt.bar(range(1, 6), scores, color='skyblue')
plt.axhline(scores.mean(), color='red', linestyle='--', label='Promedio RÂ²')
plt.title("ğŸ“Š Resultados de RÂ² por Fold (K-Fold CV)")
plt.xlabel("Fold")
plt.ylabel("RÂ² Score")
plt.ylim(0.4, 0.8)
plt.legend()
plt.show()
```

### ğŸ’¬ **ExplicaciÃ³n : Â¿Por quÃ© usar K-Fold Cross Validation?**

ğŸ” Cuando dividimos los datos una sola vez en train/test, nuestro resultado puede **variar segÃºn la suerte**. 

Â¿QuÃ© pasa si justo los datos difÃ­ciles quedaron en el set de prueba? ğŸ¤·â€â™‚ï¸

ğŸ’¡ **K-Fold Cross Validation** divide el dataset en **K partes**, entrena y evalÃºa **K veces**, cada vez con un grupo distinto de prueba.

âœ”ï¸ AsÃ­ obtenemos **K evaluaciones independientes**, y al calcular el **promedio**, tenemos una medida mÃ¡s **estable y confiable** del rendimiento del modelo.

ğŸ“Œ En esta prÃ¡ctica usamos **RÂ²**, que indica quÃ© tan bien el modelo explica la variabilidad del precio de la vivienda. Un RÂ² alto y estable entre folds es buena seÃ±al ğŸ§ ğŸ“ˆ

### âœ… **ReflexiÃ³n final**

> Validar con K-Fold es como hacer un chequeo mÃ©dico en cinco clÃ­nicas diferentes: si todos coinciden, el diagnÃ³stico es confiable ğŸ¥âœ…
>  Esta tÃ©cnica no solo mejora la evaluaciÃ³n, sino que es base para mÃ©todos avanzados como optimizaciÃ³n de hiperparÃ¡metros y ensamblado de modelos.
>  Â¡Nunca mÃ¡s confÃ­es en un solo split de datos! ğŸ˜‰

### ğŸ’¡ Tips :

- Usa `shuffle=True` para que los folds sean aleatorios.
- CombÃ­nalo con `GridSearchCV` para elegir los mejores parÃ¡metros.
- Aumenta `n_splits` si tienes muchos datos; usa `K=10` para validaciÃ³n mÃ¡s fina.
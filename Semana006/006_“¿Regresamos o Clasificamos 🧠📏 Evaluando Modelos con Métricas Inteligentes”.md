# **â€œÂ¿Regresamos o Clasificamos? ğŸ§ ğŸ“ Evaluando Modelos con MÃ©tricas Inteligentesâ€**

### ğŸ¯ **Objetivo**

Entrenar dos modelos sobre el dataset **California Housing**:

1. Un modelo de **regresiÃ³n** para predecir el valor promedio de una vivienda.
2. Un modelo de **clasificaciÃ³n binaria**, transformando el target en:
   - ğŸŸ¢ "1" si el precio â‰¥ 2.0
   - ğŸ”´ "0" si el precio < 2.0

Se evaluarÃ¡n ambos con sus mÃ©tricas especÃ­ficas y se compararÃ¡n los resultados visualmente.

### ğŸ“¦ **Dataset**

Se utiliza el dataset oficial de `sklearn.datasets`.

ğŸ”— URL oficial:
 https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html

### ğŸ§° **Paso a Paso**

#### ğŸ”¹ Paso 1: Importar librerÃ­as necesarias

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
```

#### ğŸ”¹ Paso 2: Cargar y preparar los datos

```python
# Cargar dataset
data = fetch_california_housing(as_frame=True)
df = data.frame

# Escalar datos
X = df.drop(columns='MedHouseVal')
y_reg = df['MedHouseVal']  # para regresiÃ³n

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Crear variable binaria para clasificaciÃ³n
y_clf = (y_reg >= 2.0).astype(int)
```

### ğŸ§® MODELO 1: REGRESIÃ“N

#### ğŸ”¹ Paso 3: DivisiÃ³n y entrenamiento regresiÃ³n

```python
X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_scaled, y_reg, test_size=0.2, random_state=42)
model_reg = LinearRegression()
model_reg.fit(X_train_r, y_train_r)
y_pred_r = model_reg.predict(X_test_r)
```

#### ğŸ”¹ Paso 4: EvaluaciÃ³n regresiÃ³n

```python
mse = mean_squared_error(y_test_r, y_pred_r)
mae = mean_absolute_error(y_test_r, y_pred_r)
r2 = r2_score(y_test_r, y_pred_r)

print(f"ğŸ“‰ MSE: {mse:.4f}")
print(f"ğŸ“Š MAE: {mae:.4f}")
print(f"ğŸ“ˆ RÂ²: {r2:.4f}")
```

#### ğŸ”¹ Paso 5: VisualizaciÃ³n regresiÃ³n

```python
plt.figure(figsize=(7,5))
sns.scatterplot(x=y_test_r, y=y_pred_r, alpha=0.5)
plt.plot([y_test_r.min(), y_test_r.max()], [y_test_r.min(), y_test_r.max()], 'r--')
plt.xlabel("Valor Real ğŸ ")
plt.ylabel("Valor Predicho ğŸ’¸")
plt.title("RegresiÃ³n: Real vs Predicho ğŸ“ˆ")
plt.grid(True)
plt.show()
```

### ğŸ”¢ MODELO 2: CLASIFICACIÃ“N

#### ğŸ”¹ Paso 6: DivisiÃ³n y entrenamiento clasificaciÃ³n

```python
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_scaled, y_clf, test_size=0.2, random_state=42)
model_clf = LogisticRegression()
model_clf.fit(X_train_c, y_train_c)
y_pred_c = model_clf.predict(X_test_c)
```

#### ğŸ”¹ Paso 7: EvaluaciÃ³n clasificaciÃ³n

```python
acc = accuracy_score(y_test_c, y_pred_c)
prec = precision_score(y_test_c, y_pred_c)
rec = recall_score(y_test_c, y_pred_c)
f1 = f1_score(y_test_c, y_pred_c)

print(f"âœ… Accuracy: {acc:.4f}")
print(f"ğŸ” Precision: {prec:.4f}")
print(f"ğŸ“¢ Recall: {rec:.4f}")
print(f"ğŸ¯ F1-score: {f1:.4f}")
```

#### ğŸ”¹ Paso 8: Matriz de ConfusiÃ³n

```python
cm = confusion_matrix(y_test_c, y_pred_c)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["< 2.0", "â‰¥ 2.0"])
disp.plot(cmap="Blues")
plt.title("ğŸ”µ Matriz de ConfusiÃ³n - ClasificaciÃ³n")
plt.show()
```

### âœ… **ReflexiÃ³n final**

> **No existe una mÃ©trica universal**. Cada mÃ©trica responde una pregunta diferente.
>  **EvalÃºa con varias mÃ©tricas**, visualiza errores y elige el modelo que mejor se ajuste a tu problema real.
>  Â¡Tus decisiones de negocio o ciencia deben basarse en datos... y en buenas mÃ©tricas! ğŸ”¬ğŸ“‰ğŸ“Š
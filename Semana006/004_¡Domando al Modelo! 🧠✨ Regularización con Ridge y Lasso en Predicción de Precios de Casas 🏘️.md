# **Â¡Domando al Modelo! ğŸ§ âœ¨ RegularizaciÃ³n con Ridge y Lasso en PredicciÃ³n de Precios de Casas ğŸ˜ï¸**

### ğŸ¯ **Objetivo**

Entrenar y comparar modelos de regresiÃ³n con **Ridge (L2)** y **Lasso (L1)** usando el dataset real **California Housing**, para identificar cÃ³mo la regularizaciÃ³n evita el sobreajuste y mejora la generalizaciÃ³n en problemas de predicciÃ³n.

### ğŸ“¦ **Dataset**

Utilizaremos el dataset de viviendas de California, disponible en `sklearn.datasets`.

ğŸ”— [URL oficial de documentaciÃ³n](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)

### ğŸ§ª **Paso a paso **

#### ğŸ”¹ Paso 1: Importar librerÃ­as necesarias ğŸ“š

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
```

#### ğŸ”¹ Paso 2: Cargar el dataset y visualizar ğŸ¡

```python
# Cargar el dataset
data = fetch_california_housing(as_frame=True)
X = data.data
y = data.target

# Visualizar las primeras filas
X.head()
```

#### ğŸ”¹ Paso 3: Escalar caracterÃ­sticas para la regresiÃ³n âš–ï¸

```python
# Escalado de los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### ğŸ”¹ Paso 4: Dividir en entrenamiento y prueba âœ‚ï¸

```python
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
```

#### ğŸ”¹ Paso 5: Entrenar modelos Ridge y Lasso ğŸ¤–

```python
# Crear modelos con valores estÃ¡ndar de alpha
ridge = Ridge(alpha=1.0)
lasso = Lasso(alpha=0.1)

# Entrenar modelos
ridge.fit(X_train, y_train)
lasso.fit(X_train, y_train)
```

#### ğŸ”¹ Paso 6: Realizar predicciones ğŸ”®

```python
y_pred_ridge = ridge.predict(X_test)
y_pred_lasso = lasso.predict(X_test)
```

#### ğŸ”¹ Paso 7: Evaluar modelos con mÃ©tricas ğŸ“

```python
# Calcular mÃ©tricas
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)

mse_lasso = mean_squared_error(y_test, y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)

# Mostrar resultados
print(f"ğŸ“˜ Ridge - MSE: {mse_ridge:.4f}, RÂ²: {r2_ridge:.4f}")
print(f"ğŸ“• Lasso - MSE: {mse_lasso:.4f}, RÂ²: {r2_lasso:.4f}")
```

#### ğŸ”¹ Paso 8: Visualizar y comparar ğŸ“Š

```python
# GrÃ¡fica comparativa de predicciÃ³n vs real
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_ridge, color='blue', alpha=0.5, label='Ridge')
plt.scatter(y_test, y_pred_lasso, color='green', alpha=0.5, label='Lasso')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal')
plt.xlabel("Precio real ğŸ·ï¸")
plt.ylabel("Precio predicho ğŸ’¸")
plt.title("ComparaciÃ³n de predicciones: Ridge vs Lasso")
plt.legend()
plt.grid(True)
plt.show()
```

### ğŸ’¬ **ExplicaciÃ³n : Â¿Por quÃ© usar Ridge y Lasso?**

ğŸ“Œ A veces, los modelos ajustan demasiado bien los datos de entrenamiento, memorizando patrones ruidosos. Esto es **overfitting**. La **regularizaciÃ³n actÃºa como freno** para evitarlo.

ğŸ§° Ridge:

- Penaliza coeficientes grandes.
- Ãštil cuando **todas las variables aportan algo**.
- No elimina variables, solo reduce su impacto.

ğŸ§¹ Lasso:

- Puede llevar coeficientes a **cero**.
- Ãštil cuando **algunas variables son irrelevantes**.
- Ayuda a seleccionar las variables mÃ¡s importantes.

âœ”ï¸ Ambos modelos te permiten lograr un balance entre **precisiÃ³n y simplicidad**, lo cual es esencial para sistemas que deben generalizar bien.

### âœ… **ReflexiÃ³n final**

> Elegir entre Ridge y Lasso depende de tu objetivo:
>
> - Â¿Quieres un modelo mÃ¡s simple con menos variables? ğŸ‘‰ Usa **Lasso**.
> - Â¿Prefieres mantener todas las variables pero reducir el sobreajuste? ğŸ‘‰ Usa **Ridge**.
>
> Â¡La regularizaciÃ³n es tu aliada para construir modelos robustos, claros y eficientes! ğŸ’ªğŸ¤–

### ğŸ’¡ Tips :

- ğŸ” Prueba diferentes valores de `alpha` y observa su efecto.
- ğŸ“‰ Usa validaciÃ³n cruzada para elegir el `alpha` Ã³ptimo (`GridSearchCV`).
- ğŸ”¢ Explora quÃ© coeficientes se eliminan con Lasso: Â¡te sorprenderÃ¡s!
# **"Â¡Regulariza tu Barrio! ğŸ¡ğŸ§  CÃ³mo Ridge y Lasso Predicen Mejor que Adivinar"**

### ğŸ¯ **Objetivo**

Demostrar la **importancia de dividir adecuadamente los datos** en entrenamiento y prueba para evitar sobreajuste, mientras se comparan dos modelos de regresiÃ³n regularizada: **Ridge** (L2) y **Lasso** (L1), usando el dataset California Housing.

### ğŸ“¦ **Dataset**

Se usarÃ¡ el dataset **California Housing** disponible en `sklearn.datasets`.

ğŸ”— **URL oficial**:
 https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html

### ğŸ§ª **Paso a paso**

#### ğŸ”¹ Paso 1: Cargar librerÃ­as ğŸ§°

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
```

#### ğŸ”¹ Paso 2: Cargar y explorar el dataset ğŸ˜ï¸

```python
# Cargar los datos
california = fetch_california_housing(as_frame=True)
df = california.frame

# Visualizar las primeras filas
df.head()
```

#### ğŸ”¹ Paso 3: Dividir en variables y aplicar escalado âš–ï¸

```python
# Separar variables predictoras y objetivo
X = df.drop(columns='MedHouseVal')
y = df['MedHouseVal']

# Escalar las caracterÃ­sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### ğŸ”¹ Paso 4: DivisiÃ³n en Training/Test ğŸ§ âœ‚ï¸

```python
# DivisiÃ³n 80/20
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Verificar tamaÃ±os
print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")
```

#### ğŸ”¹ Paso 5: Entrenar Ridge y Lasso ğŸ¤–

```python
# Crear y entrenar modelos
ridge = Ridge(alpha=1.0)
lasso = Lasso(alpha=0.1)

ridge.fit(X_train, y_train)
lasso.fit(X_train, y_train)
```

#### ğŸ”¹ Paso 6: Hacer predicciones ğŸ”®

```python
y_pred_ridge = ridge.predict(X_test)
y_pred_lasso = lasso.predict(X_test)
```

#### ğŸ”¹ Paso 7: Evaluar los modelos ğŸ“

```python
# MÃ©tricas para Ridge
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)

# MÃ©tricas para Lasso
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)

print(f"ğŸ“˜ Ridge - MSE: {mse_ridge:.4f}, RÂ²: {r2_ridge:.4f}")
print(f"ğŸ“• Lasso - MSE: {mse_lasso:.4f}, RÂ²: {r2_lasso:.4f}")
```

#### ğŸ”¹ Paso 8: Visualizar comparaciones ğŸ“Š

```python
# GrÃ¡fica comparativa
plt.figure(figsize=(8, 6))
plt.plot(y_test.values, label='Valor Real', color='black')
plt.plot(y_pred_ridge, label='Ridge', alpha=0.7)
plt.plot(y_pred_lasso, label='Lasso', alpha=0.7)
plt.title("ComparaciÃ³n de predicciones ğŸ ")
plt.xlabel("Ãndice de muestra")
plt.ylabel("Precio medio")
plt.legend()
plt.show()
```

### ğŸ’¬ **ExplicaciÃ³n:  Â¿Por quÃ© dividir los datos?**

ğŸ“Œ Imagina que estÃ¡s entrenando a un estudiante con ejemplos para un examen. Si luego le das el mismo examen que usaste en clase, no sabrÃ¡s si **realmente aprendiÃ³ o solo memorizÃ³**.

ğŸ” Lo mismo pasa en Machine Learning:

- Si entrenas y pruebas con los **mismos datos**, el modelo se puede **"sobreajustar"**: aprende demasiado bien los ejemplos, pero falla en casos nuevos.
- Dividir los datos permite **medir con realismo la capacidad del modelo para generalizar** ğŸ§ 

âš ï¸ Incluso un modelo regularizado (como Ridge o Lasso) necesita una correcta divisiÃ³n para evitar falsas expectativas de desempeÃ±o.

### âœ… **ReflexiÃ³n Final**

> Ridge y Lasso no solo ajustan una lÃ­nea, sino que le dicen al modelo: **â€œNo te sobrecompliquesâ€**.
>  Compararlos te ayuda a elegir el balance ideal entre **simplicidad y precisiÃ³n**.
>  Â¡Y recuerda siempre dividir tus datos antes de entrenar! âœ‚ï¸ğŸ“š

### ğŸ’¡ Tips:

- ğŸ“Œ Usa `GridSearchCV` para encontrar el mejor valor de `alpha`.
- ğŸ”„ Repite con validaciÃ³n cruzada para mayor robustez.
- ğŸ“ Observa quÃ© coeficientes anula Lasso: es Ãºtil para **selecciÃ³n de caracterÃ­sticas**.